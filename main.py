from graph_logic import query_with_graph
import streamlit as st
from dotenv import load_dotenv
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

load_dotenv()

st.set_page_config(page_title="Food Allergy AI Agent", layout="wide")

# 1. åˆå§‹åŒ–è®°å¿†å’Œå¤„ç†çŠ¶æ€
msgs = StreamlitChatMessageHistory(key="messages")
if "last_processed_file" not in st.session_state:
    st.session_state.last_processed_file = None

st.title("ğŸ¥— Food Allergy AI Agent")
st.markdown("ä¸Šä¼ é£Ÿå“å›¾ç‰‡æˆ–ç›´æ¥æé—®ï¼Œæˆ‘ä¼šå¸®ä½ æ£€æŸ¥è¿‡æ•åŸã€‚")

# 2. ä¾§è¾¹æ ï¼šä¸Šä¼ åŠŸèƒ½
with st.sidebar:
    st.header("å›¾ç‰‡è¯†åˆ«")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ é£Ÿå“åŒ…è£…æˆ–é…æ–™è¡¨å›¾ç‰‡",
        type=["jpg", "jpeg", "png"],
        key="sidebar_uploader"
    )
    if uploaded_file:
        st.image(uploaded_file, caption="å¾…å¤„ç†å›¾ç‰‡", use_container_width=True)

        if uploaded_file.name != st.session_state.last_processed_file:
            if st.button("å¼€å§‹è¯†åˆ«è¿‡æ•åŸ"):
                with st.chat_message("assistant"):
                    with st.spinner("è§†è§‰è¯†åˆ«ä¸­..."):
                        try:
                            image_bytes = uploaded_file.getvalue()
                            # å¤„ç†æµå¼ç”Ÿæˆå™¨
                            for step in query_with_graph("è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„é£Ÿå“åç§°ï¼Œå¹¶æ ¹æ®æ•°æ®åº“æŸ¥è¯¢å…¶è¿‡æ•åŸä¿¡æ¯ã€‚", image_bytes=image_bytes):
                                if step["node"] == "end":
                                    response = step["generation"]

                            msgs.add_user_message("ğŸ“¸ [ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡]")
                            msgs.add_ai_message(response)
                            st.session_state.last_processed_file = uploaded_file.name
                            st.rerun()
                        except Exception as e:
                            st.error(f"è¯†åˆ«å¤±è´¥: {str(e)}")

# 3. ä¸»ç•Œé¢æ¸²æŸ“å†å²è®°å½•
for msg in msgs.messages:
    role = "user" if msg.type == "human" else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)

# 4. åº•éƒ¨æ–‡å­—é—®ç­”å…¥å£ (å¸¦æ€è€ƒè¿‡ç¨‹å±•ç¤º)
if prompt := st.chat_input("ä¾‹å¦‚ï¼šæé”¦è®°æœ‰å“ªäº›ä¸å«å¤§è±†çš„é…±ï¼Ÿ"):
    st.chat_message("user").markdown(prompt)
    msgs.add_user_message(prompt)

    with st.chat_message("assistant"):
        # ä½¿ç”¨ st.status æ˜¾ç¤º DeepSeek é£æ ¼çš„æ€è€ƒè¿‡ç¨‹
        with st.status("ğŸ” æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
            final_response = ""
            for step in query_with_graph(prompt):
                node = step.get("node")

                # åŠ¨æ€æ˜¾ç¤ºå½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹
                if node == "route_question":
                    st.write("ğŸš¦ æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜æ„å›¾...")
                elif node == "retrieve":
                    st.write("ğŸ“š æ­£åœ¨æ£€ç´¢æœ¬åœ°å‘é‡æ•°æ®åº“...")
                elif node == "sql_agent":
                    st.write("ğŸ“Š æ­£åœ¨æ„é€  SQL å¹¶åœ¨é£Ÿå“æ•°æ®åº“ä¸­æœç´¢...")
                elif node == "grade_documents":
                    st.write("âš–ï¸ æ­£åœ¨è¯„ä¼°æ‰¾åˆ°çš„èµ„æ–™æ˜¯å¦ç›¸å…³...")
                elif node == "web_search":
                    st.write("ğŸŒ æœ¬åœ°èµ„æ–™ä¸è¶³ï¼Œæ­£åœ¨å¯åŠ¨è”ç½‘æœç´¢...")
                elif node == "hallucination_grader":
                    st.write("ğŸ•µï¸ æ­£åœ¨è¿›è¡Œäº‹å®æ ¸æŸ¥ï¼Œç¡®ä¿å›ç­”æ— è¯¯...")
                elif node == "answer_grader":
                    st.write("âœ… æ­£åœ¨ç¡®è®¤å›ç­”æ˜¯å¦è§£å†³äº†æ‚¨çš„é—®é¢˜...")

                if node == "end":
                    final_response = step["generation"]
                    duration = step["duration"]
                    status.update(
                        label=f"âœ… æ€è€ƒå®Œæˆ (è€—æ—¶ {duration:.2f}ç§’)", state="complete", expanded=False)

        # æ€è€ƒå®Œæˆåï¼Œæ˜¾ç¤ºæœ€ç»ˆå›ç­”
        st.markdown(final_response)
        msgs.add_ai_message(final_response)
